{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating measures of employment density per hex grid. Data is from the Place of Work question from the 2016 census (i.e. only includes those with a \"usual place of work\"\n",
    "\n",
    "http://odesi2.scholarsportal.info/documentation/CENSUS/2016/cen16labour.html\n",
    "\n",
    "Using areal interpolation to transfer employment data from DAs, $E_d$, to hex grids, $E_h$.\n",
    "\n",
    "### $E_h = \\sum E_{d} {w_{d,h}}$\n",
    "\n",
    "### $E_h = \\sum E_{d} \\frac{A_{d \\cap h}}{A_b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With postgreSQL and PostGIS ..\n",
    "\n",
    "```sql\n",
    "-- creating a spatial index for the hex grid to speed up the intersection\n",
    "\n",
    "DROP INDEX IF EXISTS hex_grid_200m_gix;\n",
    "CREATE INDEX hex_grid_200m_gix ON hex_grid_200m USING GIST (geom);\n",
    "\n",
    "-- creating an area column $A_b$ for the dissemination area boundaries\n",
    "\n",
    "ALTER TABLE zones_DA16 ADD COLUMN area double precision;\n",
    "UPDATE zones_DA16 SET area = ST_AREA(geom);\n",
    "\n",
    "-- Join the employment data to DAs\n",
    "\n",
    "DROP TABLE IF EXISTS temp_DA_emp;\n",
    "CREATE TABLE temp_DA_emp AS ( \n",
    "    SELECT\n",
    "    zones_DA16.geom AS geom,\n",
    "    zones_DA16.dauid AS dauid,\n",
    "    zones_DA16.cduid AS cduid,\n",
    "    zones_DA16.area AS area,\n",
    "    coalesce(table_DA_emp_2016.emp2016,20) AS emp2016 \n",
    "    -- nulls to 20 (estimating suppressed has 20 emp, as all under 40 are suppresed (i.e. the mean))\n",
    "    FROM zones_DA16\n",
    "    LEFT OUTER JOIN \n",
    "    table_DA_emp_2016 ON table_DA_emp_2016.dauid = zones_DA16.dauid\n",
    ");   \n",
    "\n",
    "-- create a spatial index for this dauid polygon file\n",
    "\n",
    "DROP INDEX IF EXISTS temp_DA_emp_gix;\n",
    "CREATE INDEX temp_DA_emp_gix ON temp_DA_emp USING GIST (geom); \n",
    "\n",
    "-- intersecting with the hex grid, then grouping to get the a set of weights of block to hex grid\n",
    "\n",
    "CREATE TABLE temp_int_DA16_hex AS\n",
    "(\n",
    "SELECT\n",
    "hex_grid_200m.id AS hexid,\n",
    "temp_DA_emp.dauid AS dauid,\n",
    "temp_DA_emp.area AS area_full,\n",
    "ST_Intersection(hex_grid_200m.geom,temp_DA_emp.geom) AS geom\n",
    "FROM\n",
    "hex_grid_200m INNER JOIN temp_DA_emp ON ST_Intersects(hex_grid_200m.geom,temp_DA_emp.geom)\n",
    ");\n",
    "\n",
    "-- update area of intersected geoms\n",
    "\n",
    "ALTER TABLE temp_int_DA16_hex ADD COLUMN area_int double precision;\n",
    "UPDATE temp_int_DA16_hex SET area_int = ST_AREA(geom);\n",
    "\n",
    "ALTER TABLE temp_int_DA16_hex ADD COLUMN area_ratio double precision;\n",
    "UPDATE temp_int_DA16_hex SET area_ratio = area_int / area_full;\n",
    "\n",
    "-- grouping by hex and DA unique IDs - i.e. this is a weights table that can be used for apportioning data\n",
    "\n",
    "CREATE TABLE weights_da16_hex AS\n",
    "(\n",
    "SELECT\n",
    "hexid,\n",
    "dauid,\n",
    "sum(area_ratio) AS weight\n",
    "FROM\n",
    "temp_int_DA16_hex\n",
    "GROUP BY dauid, hexid\n",
    "ORDER BY dauid, hexid\n",
    ");\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the weights table to apportion the employment data to the hex grid\n",
    "\n",
    "```sql\n",
    "-- joining the employment to the weights table\n",
    "-- multiplying the employment by the weight and aggregating by hex grid\n",
    "\n",
    "DROP TABLE IF EXISTS out_data_hex_emp2016;\n",
    "CREATE TABLE out_data_hex_emp2016 AS (\n",
    "    WITH temp_weight_join AS (\n",
    "        SELECT\n",
    "        weights_da16_hex.dauid AS dauid,\n",
    "        weights_da16_hex.hexid AS hexid,\n",
    "        weights_da16_hex.weight AS weight,\n",
    "        temp_DA_emp.emp2016 AS emp2016\n",
    "        FROM weights_da16_hex\n",
    "        INNER JOIN temp_DA_emp ON temp_DA_emp.dauid = weights_da16_hex.dauid\n",
    "    ) \n",
    "    SELECT\n",
    "    temp_weight_join.hexid AS hexid,\n",
    "    SUM(temp_weight_join.weight * temp_weight_join.emp2016) AS emp2016\n",
    "    FROM temp_weight_join GROUP BY temp_weight_join.hexid\n",
    ");\n",
    "\n",
    "-- Create a density column                                                                 \n",
    "                                                                  \n",
    "ALTER TABLE out_data_hex_emp2016 ADD COLUMN empdensity2016 double precision;\n",
    "UPDATE out_data_hex_emp2016 SET empdensity2016 = emp2016 / (34641.0161513719 / (1000 * 1000));\n",
    "                                                                                               \n",
    "-- lets write that to a file\n",
    "\n",
    "\\COPY out_data_hex_emp2016 TO 'out_data_hex_emp2016.csv' WITH (FORMAT CSV, HEADER);\n",
    "\n",
    "-- we can delete the temp tables if we want, but they take a little while to compute so it may be nice to keep them if space isnt an issue\n",
    "\n",
    "DROP TABLE temp_DA_emp;\n",
    "DROP TABLE temp_int_DA16_hex;\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
